{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae378e3",
   "metadata": {},
   "source": [
    "# <font color='289C4E'>Exploration Numérique 2\n",
    "**Élèves**: Sadegh ABDERRAHIM & Gabriel PEREIRA DE CARVALHO & Otávio RIBAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bd219",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>Table des matières<font><a class='anchor' id='top'></a>\n",
    "- [Python setup](#setup)\n",
    "- [Exercice 1](#1)\n",
    "- [Exercice 2](#2)\n",
    "- [Exercice 3](#3)\n",
    "- [Exercice 4](#4)\n",
    "- [Exercice 5](#5)\n",
    "- [Exercice 6](#6)\n",
    "- [Exercice 7](#7)\n",
    "- [Exercice 8](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7286c3d",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='gray'>Python setup</font></h2> <a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee77e7f",
   "metadata": {},
   "source": [
    "Dans cette section, on va importer tous les paquets qu'on ira utiliser plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc94b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t as student\n",
    "from scipy.stats import f as fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172556e",
   "metadata": {},
   "source": [
    "On profite aussi pour créer les tableaux qu'on utilisera pour les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e015211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([13, 130, 39, 33, 10,\n",
    "             13, 68, 18, 3, 11,\n",
    "             38, 23, 60, 5, 9,\n",
    "             59, 5, 86, 22, 70,\n",
    "             58, 3, 167, 15, 30,\n",
    "             8, 20, 67, 26, 19])\n",
    "n = len(X)\n",
    "Y = np.array([14, 8, 20, 3, 138,\n",
    "             122, 78, 69, 111, 3,\n",
    "             128, 31, 18, 35, 111,\n",
    "             109, 36, 27, 32, 35,\n",
    "             12, 27, 8, 3, 80,\n",
    "             91, 68, 66, 176, 15])\n",
    "p = len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b0cef",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 1</font></h2> <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b8878",
   "metadata": {},
   "source": [
    "La vraisemblance est $$l(\\theta) = \\left(\\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma_0} e^{-\\frac{(X_i-\\mu_0)^2}{2\\sigma_0^2}}\\right)\\left(\\prod_{j=1}^p \\frac{1}{\\sqrt{2\\pi}\\sigma_1} e^{-\\frac{(Y_j-\\mu_1)^2}{2\\sigma_1^2}}\\right) \\\\ \\implies \\ln(l(\\theta)) = -\\frac{n+p}{2}\\ln(2\\pi) - n\\ln(\\sigma_0) -p\\ln(\\sigma_1) - \\frac{1}{2\\sigma_0^2}\\sum_{i=1}^n(X_i - \\mu_0)^2 - \\frac{1}{2\\sigma_1^2}\\sum_{j=1}^p(Y_j - \\mu_1)^2.$$\n",
    "Alors, $\\nabla_\\theta \\ln(l(\\theta)) = 0$ donne que la log-vraisemblance est maximisée en\n",
    "$$\\begin{align}\n",
    "\\begin{cases}\n",
    "\\hat{\\mu}_0 &= \\frac{1}{n}\\sum_{i=1}^n X_i \\\\\n",
    "\\hat{\\mu}_1 &= \\frac{1}{p}\\sum_{j=1}^p Y_j \\\\\n",
    "\\hat{\\sigma}_0^2 &= \\frac{1}{n}\\sum_{i=1}^n (X_i - \\hat{\\mu}_0)^2 \\\\\n",
    "\\hat{\\sigma}_1^2 &= \\frac{1}{p}\\sum_{j=1}^p (Y_j - \\hat{\\mu}_1)^2\n",
    "\\end{cases}\n",
    "\\end{align}$$\n",
    "on conclue $\\hat{\\theta}_{MV} = \\left(\\bar{X}_n, \\bar{Y}_p, \\frac{1}{n}\\sum_{i=1}^n (X_i - \\bar{X}_n)^2, \\frac{1}{p}\\sum_{j=1}^p (Y_j - \\bar{Y}_p)^2  \\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a039e",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 2</font></h2> <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5a3c97",
   "metadata": {},
   "source": [
    "Le rapport de vraisemblance est $$ G(Z, \\theta) = \\frac{\\sigma_1^2}{\\sigma_0^2} \\frac{(p-1)\\sum_{i=1}^n (X_i - \\bar{X}_n)^2}{(n-1)\\sum_{j=1}^p (Y_j - \\hat{Y}_p)^2} \\sim F(n-1, p-1).$$\n",
    "\n",
    "Posons la statistique de test $$ T(Z) = \\frac{(p-1)\\sum_{i=1}^n (X_i - \\bar{X}_n)^2}{(n-1)\\sum_{j=1}^p (Y_j - \\bar{Y}_p)^2} $$\n",
    "et la région de réjet $$ \\mathcal{R}_\\alpha = \\left\\{Z \\in \\mathbb{R}^{n+p} : T(Z) \\in \\left(0, f_{n-1, p-1}^{\\frac{\\alpha}{2}}\\right) \\cup  \\left(f_{n-1, p-1}^{1-\\frac{\\alpha}{2}}, +\\infty \\right) \\right\\} $$\n",
    "où $f_{n-1, p-1}^{1-\\frac{\\alpha}{2}}$ est le quantile d'ordre $1 - \\frac{\\alpha}{2}$ de la loi de Fisher $F(n-1,p-1)$.\n",
    "\n",
    "Sous $H_0$, prenons $\\theta \\in \\Theta$ tel que $\\sigma_0^2 = \\sigma_1^2 \\implies T(Z) = \\frac{\\sigma_1^2}{\\sigma_0^2}T(Z) \\sim F(n-1, p-1)$. On a\n",
    "$$\\begin{align}\n",
    "\\mathbb{P}_\\theta \\left( Z \\in \\mathcal{R}_\\alpha \\right) &= \\mathbb{P}_\\theta \\left( T(Z) \\in \\left(0, f_{n-1, p-1}^{\\frac{\\alpha}{2}}\\right) \\cup  \\left(f_{n-1, p-1}^{1-\\frac{\\alpha}{2}}, +\\infty \\right) \\right)\\\\\n",
    "&= \\mathbb{P}_\\theta \\left( \\frac{\\sigma_1^2}{\\sigma_0^2}T(Z) \\in \\left(0, f_{n-1, p-1}^{\\frac{\\alpha}{2}}\\right) \\cup  \\left(f_{n-1, p-1}^{1-\\frac{\\alpha}{2}}, +\\infty \\right) \\right) \\\\\n",
    "&= \\alpha.\n",
    "\\end{align}$$\n",
    "Donc, le test a bien niveau $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92039b4c",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 3</font></h2> <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6073a",
   "metadata": {},
   "source": [
    "On veut calculer $\\hat{\\alpha}(Z)$ tel que $$ T(Z) = f_{n-1, p-1}^{\\frac{\\hat{\\alpha}(Z)}{2}}. $$\n",
    "Soit $\\Phi_{F(n-1,p-1)}$ la fonction de répartition de la loi de Fisher à $(n-1, p-1)$ degrés de liberté, on a \n",
    "$$ \\frac{\\hat{\\alpha}(Z)}{2} = \\Phi_{F(n-1,p-1)}(T(Z)) \\implies \\hat{\\alpha}(Z) = 2\\Phi_{F(n-1,p-1)}\\left( \\frac{(p-1)\\sum_{i=1}^n (X_i - \\bar{X}_n)^2}{(n-1)\\sum_{j=1}^p (Y_j - \\bar{Y}_p)^2} \\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0e60f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22894413803747107\n"
     ]
    }
   ],
   "source": [
    "X_mean = np.mean(X)\n",
    "var_X = np.sum((X - X_mean)**2)/(n-1)\n",
    "Y_mean = np.mean(Y)\n",
    "var_Y = np.sum((Y - Y_mean)**2)/(p-1)\n",
    "\n",
    "statistique_test = var_X/var_Y\n",
    "p_valeur = 2*fisher.cdf(statistique_test, n-1, p-1)\n",
    "print(p_valeur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7241c1d",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 4</font></h2> <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7daf2bc",
   "metadata": {},
   "source": [
    "On remarque que $X_i \\sim \\mathcal{N}(\\mu_0, \\sigma) \\implies \\hat{\\mu}_0 = \\bar{X}_n \\sim \\mathcal{N}\\left(\\mu_0, \\frac{\\sigma^2}{n}\\right)$ et analogiquement, $\\hat{\\mu}_1 = \\bar{Y}_p \\sim \\mathcal{N}\\left(\\mu_1, \\frac{\\sigma^2}{p}\\right)$.\n",
    "\n",
    "Donc $$\\hat{\\mu}_0 - \\hat{\\mu}_1 \\sim \\mathcal{N}\\left(\\mu_0 - \\mu_1, \\sigma^2\\left(\\frac{n+p}{np}\\right)\\right).$$\n",
    "Pour travailler avec les quantilles de la loi normale centrée réduite, on a $$\\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{\\sigma}\\right) \\sim \\mathcal{N}(0,1).$$\n",
    "\n",
    "Une fois que $\\sigma^2$ est inconnu, on va utiliser la variance de l'échantillon $S_{n,p}^2$ donné par\n",
    "$$ S_{n,p}^2 = \\frac{1}{n + p - 2}\\left(\\sum_{i=1}^n (X_i - \\bar{X}_n)^2 +  \\sum_{j=1}^n (Y_j - \\bar{Y}_p)^2\\right)$$\n",
    "on remarque que $\\mathbb{E}[S_{n,p}^2] = \\sigma^2$.\n",
    "\n",
    "Par le théorème de Gosset(Théorème IV-3.24) on a $ (n+p-2)\\frac{S_{n,p}^2}{\\sigma^2} \\sim \\chi_{n+p-2}^2$.\n",
    "\n",
    "Alors, on a $$ \\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{S_{n,p}}\\right) \\sim t_{n+p-2}$$\n",
    "\n",
    "ce qui donne\n",
    "\n",
    "$$\\begin{align}\n",
    "&\\mathbb{P}_\\theta \\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{S_{n,p}}\\right) \\in \\left[ -t_{n+p-2}^{1-\\frac{\\alpha}{2}}, t_{n+p-2}^{1-\\frac{\\alpha}{2}} \\right] \\right) = 1 - \\alpha\\\\\n",
    "\\iff &\\mathbb{P}_\\theta \\left( (\\mu_0 - \\mu_1) \\in \\left[(\\hat{\\mu}_0 - \\hat{\\mu}_1) - S_{n,p} \\sqrt{\\frac{n+p}{np}} t_{n+p-2}^{1-\\frac{\\alpha}{2}}, (\\hat{\\mu}_0 - \\hat{\\mu}_1) + S_{n,p} \\sqrt{\\frac{n+p}{np}}t_{n+p-2}^{1-\\frac{\\alpha}{2}} \\right] \\right) = 1 - \\alpha.\n",
    "\\end{align}$$\n",
    "\n",
    "On en conclue, que l'intervalle de confiance est $$ \\left[(\\hat{\\mu}_0 - \\hat{\\mu}_1) - S_{n,p} \\sqrt{\\frac{n+p}{np}} t_{n+p-2}^{1-\\frac{\\alpha}{2}}, (\\hat{\\mu}_0 - \\hat{\\mu}_1) + S_{n,p} \\sqrt{\\frac{n+p}{np}}t_{n+p-2}^{1-\\frac{\\alpha}{2}} \\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77d72c",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 5</font></h2> <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1e81c",
   "metadata": {},
   "source": [
    "Soit $Z = (X_1,...,X_n, Y_1,...,Y_p)$ et $\\theta_0 = (\\mu_0, \\mu_0, \\sigma)$. \n",
    "\n",
    "Posons la statistique de test $$ T(Z) = \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\hat{\\mu}_0 - \\hat{\\mu}_1}{S_{n,p}}\\right).$$\n",
    "En utilisant l'intervalle de confiance de la question précedente, on remarque que sous $H_0$ on a $$ P_{\\theta_0}\\left( T(Z) \\in \\left[ -t_{n+p-2}^{1-\\frac{\\alpha}{2}}, t_{n+p-2}^{1-\\frac{\\alpha}{2}} \\right] \\right) = 1-\\alpha \\implies P_{\\theta_0}\\left( T(Z) \\in (-\\infty, -t_{n+p-2}^{1-\\frac{\\alpha}{2}}) \\cup (t_{n+p-2}^{1-\\frac{\\alpha}{2}}, +\\infty)\\right) = \\alpha.$$\n",
    "\n",
    "Donc, la région de rejet $\\mathcal{R}_\\alpha = \\left\\{ Z \\in \\mathbb{R}^{n+p} : T(Z) \\in (-\\infty, -t_{n+p-2}^{1-\\frac{\\alpha}{2}}) \\cup (t_{n+p-2}^{1-\\frac{\\alpha}{2}}, +\\infty) \\right\\}$ définit un test d'hypothèse de niveau $\\alpha$.\n",
    "\n",
    "Pour $\\alpha = 0,01$ on a $\\mathcal{R}_{0,01} = \\left\\{ Z \\in \\mathbb{R}^{n+p} : T(Z) \\in (-\\infty, -t_{n+p-2}^{0,995}) \\cup (t_{n+p-2}^{0,995}, +\\infty) \\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33290a49",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 6</font></h2> <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410a2d57",
   "metadata": {},
   "source": [
    "On veut calculer $\\hat{\\alpha}(Z)$ tel que $$ T(Z) = t_{n+p-2}^{1 - \\frac{\\hat{\\alpha}(Z)}{2}}. $$\n",
    "Soit $\\Phi_{t_{n+p-2}}$ la fonction de répartition de la loi Student à $n+p-2$ degrés de liberté, on a \n",
    "$$ 1 - \\frac{\\hat{\\alpha}(Z)}{2} = \\Phi_{t_{n+p-2}}(T(Z))) \\implies \\hat{\\alpha}(Z) = 2 - 2\\Phi_{t_{n+p-2}}\\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\hat{\\mu}_0 - \\hat{\\mu}_1}{S_{n,p}}\\right) \\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b394e06",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 7</font></h2> <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae6527",
   "metadata": {},
   "source": [
    "On veut construire un test de niveau $\\alpha = 0,01$ de l'hypothèse\n",
    "$$ H_0: \\mu_0 - \\mu_1 \\leq 0 \\quad \\text{contre} \\quad H_1: \\mu_0 - \\mu_1 > 0. $$\n",
    "\n",
    "Posons la statistique de test $$ T(Z) = \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\hat{\\mu}_0 - \\hat{\\mu}_1}{S_{n,p}}\\right)$$\n",
    "et la région de rejet $$\\mathcal{R}_\\alpha = \\left\\{ Z \\in \\mathbb{R}^{n+p} : T(Z) > t_{n+p-2}^{1-\\alpha} \\right\\} \\implies \\mathcal{R}_{0,01} = \\left\\{ Z \\in \\mathbb{R}^{n+p} : T(Z) > t_{n+p-2}^{0,99} \\right\\}$$\n",
    "alors on veut calculer le niveau de ce test.\n",
    "\n",
    "Sous $H_0$, prenons $\\theta \\in \\Theta \\implies \\mu_0 - \\mu_1 \\leq 0$. On a\n",
    "$$\\begin{align}\n",
    "\\mathbb{P}_\\theta \\left( Z \\in \\mathcal{R}_\\alpha \\right) &= \\mathbb{P}_\\theta \\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\hat{\\mu}_0 - \\hat{\\mu}_1}{S_{n,p}}\\right) > t_{n+p-2}^{1-\\alpha} \\right)\\\\\n",
    "&= \\mathbb{P}_\\theta \\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{S_{n,p}}\\right) + \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\mu_0 - \\mu_1}{S_{n,p}}\\right) > t_{n+p-2}^{1-\\alpha} \\right) \\\\\n",
    "&\\leq \\mathbb{P}_\\theta \\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{S_{n,p}}\\right) > t_{n+p-2}^{1-\\alpha} \\right) \\\\\n",
    "&= \\alpha \n",
    "\\end{align}$$\n",
    "car $\\sqrt{\\frac{np}{n+p}}\\left(\\frac{(\\hat{\\mu}_0 - \\hat{\\mu}_1) - (\\mu_0 - \\mu_1)}{S_{n,p}}\\right) \\sim t_{n+p-2}$. On en conclue que le test a bien niveau $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41425480",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> <font color='blue'>Exercice 8</font></h2> <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48100474",
   "metadata": {},
   "source": [
    "On veut calculer $\\hat{\\alpha}(Z)$ tel que $$ T(Z) = t_{n+p-2}^{1 - \\hat{\\alpha}(Z)}. $$\n",
    "Soit $\\Phi_{t_{n+p-2}}$ la fonction de répartition de la loi Student à $n+p-2$ degrés de liberté, on a \n",
    "$$ 1 - \\hat{\\alpha}(Z) = \\Phi_{t_{n+p-2}}(T(Z))) \\implies \\hat{\\alpha}(Z) = 1 - \\Phi_{t_{n+p-2}}\\left( \\sqrt{\\frac{np}{n+p}}\\left(\\frac{\\hat{\\mu}_0 - \\hat{\\mu}_1}{S_{n,p}}\\right) \\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcc9244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441249191582982\n"
     ]
    }
   ],
   "source": [
    "X_mean = np.mean(X)\n",
    "Y_mean = np.mean(Y)\n",
    "Snp = ( np.sum((X - X_mean)**2) + np.sum((Y - Y_mean)**2) )/(n+p-2)\n",
    "\n",
    "statistique_test = np.sqrt((n*p)/(n + p))*((X_mean - Y_mean)/np.sqrt(Snp))\n",
    "p_valeur = 1 - student.cdf(statistique_test, n+p-2)\n",
    "print(p_valeur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
